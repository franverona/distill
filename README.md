# Distill

A local REST API that accepts a URL, scrapes its content, and returns a summary
generated by a local LLM via [Ollama](https://ollama.com).

Built with FastAPI, SQLAlchemy, and httpx.

---

## Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) — fast Python package manager
- [Ollama](https://ollama.com) — local LLM runner

---

## Setup

### 1. Install Ollama

```bash
# macOS
brew install ollama

# Linux (one-liner from ollama.com)
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. Start Ollama and pull the model

```bash
# Start the Ollama server (runs in the background)
ollama serve

# Pull the default model used by Distill
ollama pull llama3.2
```

### 3. Clone and configure the project

```bash
cp .env.example .env
```

Open `.env` and adjust `OLLAMA_BASE_URL` or `OLLAMA_MODEL` if you want to use
a different model.

### 4. Install dependencies

```bash
uv sync
```

### 5. Install pre-commit hooks

```bash
uv run pre-commit install
uv run pre-commit install --hook-type commit-msg
```

### 6. Run the development server

```bash
make dev
```

The API will be available at <http://localhost:8000>.
Interactive docs: <http://localhost:8000/docs>

---

## Scripts

| Command | Description |
|---|---|
| `make dev` | Start the development server (auto-reload) |
| `make lint` | Check for linting issues |
| `make lint-fix` | Check and auto-fix linting issues |
| `make format` | Format the code |

## Running CI locally

Install [act](https://github.com/nektos/act) and [Docker](https://www.docker.com), then:

```bash
# macOS
brew install act

# Run the full CI workflow
act

# Run only the lint job
act -j lint
```

Configuration is in `.actrc`. The first run will pull the Docker image, which may take a moment.

---

## Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/summarize` | Scrape a URL and return a summary |
| `GET`  | `/summarize/history` | List past summaries (paginated) |
| `GET`  | `/summarize/history/{id}` | Get a single summary by ID |

### Example request

```bash
curl -X POST http://localhost:8000/summarize \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

---

## Project Structure

```
app/
├── main.py          # FastAPI app + router registration
├── config.py        # Settings loaded from .env
├── database.py      # SQLAlchemy engine, session, and Base
├── models/
│   └── summary.py   # ORM model (maps to `summaries` table)
├── schemas/
│   └── summary.py   # Pydantic request/response schemas
├── routes/
│   └── summarize.py # Route handlers
├── services/
│   ├── scraper.py   # Fetches and parses HTML
│   └── ollama.py    # Calls local Ollama API
└── repositories/
    └── summary.py   # Database queries
```

---

## Architecture

Requests flow through three layers:

```
Route handler  →  Service layer  →  Repository layer  →  Database
                       ↓
                  Ollama / httpx
```

- **Routes** handle HTTP concerns (parsing input, returning responses).
- **Services** contain business logic (scraping, LLM calls).
- **Repositories** encapsulate all database access.
